{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b63af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd713a90",
   "metadata": {},
   "source": [
    "## Trying single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a905552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets in this file: \n",
      " ['analysis', 'metadata', 'musicbrainz']\n",
      "Shape: \n",
      " (8,) (8,) (11,)\n",
      "<bound method MappingHDF5.items of <HDF5 group \"/analysis\" (16 members)>>\n",
      "Items in Group21: [(22050, b'8a45e57e7de179def87adcd3f6c87876', 0., 428.56444, 4.267, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0.743, -8.403, 0, 0.727, 414.697, 105.994, 3, 1., b'TRAAMES128F42AF068')]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/M/TRAAMES128F42AF068.h5','r') as hdf:\n",
    "    \n",
    "    ls = list(hdf.keys())\n",
    "    print('List of datasets in this file: \\n', ls)\n",
    "    #List of datasets in this file: \n",
    "    #['analysis', 'metadata', 'musicbrainz']\n",
    "\n",
    "    data1 = list('analysis')\n",
    "    data2 = list('metadata')\n",
    "    data3 = list('musicbrainz')\n",
    "    analysis = np.array(data1)\n",
    "    metadata = np.array(data2)\n",
    "    musicbrainz = np.array(data3)\n",
    "    print('Shape: \\n', analysis.shape, metadata.shape, musicbrainz.shape)\n",
    "    \n",
    "    #How to access group\n",
    "    G2 = hdf.get('analysis')\n",
    "    G2_items = list(G2.items())\n",
    "    print(G2.items)\n",
    "\n",
    "    # Access the tables\n",
    "    G21 = G2.get('/analysis/songs')\n",
    "    print('Items in Group21:', np.array(G21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a567bc",
   "metadata": {},
   "source": [
    "## Trying multiple file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8543db18",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/**/TRAAMES128F42AF068.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/**/TRAAMES128F42AF068.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m hdf:      \n\u001b[1;32m      2\u001b[0m     ls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hdf\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mList of datasets in this file: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, ls)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/**/TRAAMES128F42AF068.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "with h5py.File('/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/**/TRAAMES128F42AF068.h5','r') as hdf:      \n",
    "    ls = list(hdf.keys())\n",
    "    print('List of datasets in this file: \\n', ls)\n",
    "    #List of datasets in this file: \n",
    "    #['analysis', 'metadata', 'musicbrainz']\n",
    "\n",
    "    data1 = list('analysis')\n",
    "    data2 = list('metadata')\n",
    "    data3 = list('musicbrainz')\n",
    "    analysis = np.array(data1)\n",
    "    metadata = np.array(data2)\n",
    "    musicbrainz = np.array(data3)\n",
    "    print('Shape: \\n', analysis.shape, metadata.shape, musicbrainz.shape)\n",
    "    \n",
    "    #How to access group\n",
    "    G2 = hdf.get('analysis')\n",
    "    G2_items = list(G2.items())\n",
    "    print(G2.items)\n",
    "\n",
    "    # Access the tables\n",
    "    G21 = G2.get('/analysis/songs')\n",
    "    print('Items in Group21:', np.array(G21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bae665",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebf6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets in this file: \n",
      " ['analysis', 'metadata', 'musicbrainz']\n",
      "Shape: \n",
      " (8,) (8,) (11,)\n",
      "<bound method MappingHDF5.items of <HDF5 group \"/analysis\" (16 members)>>\n",
      "Items in Group21: [-55.588 -51.9   -50.497 ... -39.241 -46.302 -47.146]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/M/TRAAMES128F42AF068.h5','r') as hdf:\n",
    "    \n",
    "    ls = list(hdf.keys())\n",
    "    print('List of datasets in this file: \\n', ls)\n",
    "    #List of datasets in this file: \n",
    "    #['analysis', 'metadata', 'musicbrainz']\n",
    "\n",
    "    data1 = list('analysis')\n",
    "    data2 = list('metadata')\n",
    "    data3 = list('musicbrainz')\n",
    "    analysis = np.array(data1)\n",
    "    metadata = np.array(data2)\n",
    "    musicbrainz = np.array(data3)\n",
    "    print('Shape: \\n', analysis.shape, metadata.shape, musicbrainz.shape)\n",
    "    \n",
    "    #How to access group\n",
    "    G2 = hdf.get('analysis')\n",
    "    G2_items = list(G2.items())\n",
    "    print(G2.items)\n",
    "\n",
    "    # Access the tables\n",
    "    G21 = G2.get('/analysis/segments_loudness_max')\n",
    "    print('Items in Group21:', np.array(G21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0212dde6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThierry Bertin-Mahieux (2010) Columbia University\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mtb2332@columbia.edu\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03malong with this program.  If not, see <http://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtables\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_h5_file_read\u001b[39m(h5filename):\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Open an existing H5 in read mode.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Same function as in hdf5_utils, here so we avoid one import\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tables'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Thierry Bertin-Mahieux (2010) Columbia University\n",
    "tb2332@columbia.edu\n",
    "\n",
    "\n",
    "This code contains a set of getters functions to access the fields\n",
    "from an HDF5 song file (regular file with one song or\n",
    "aggregate / summary file with many songs)\n",
    "\n",
    "This is part of the Million Song Dataset project from\n",
    "LabROSA (Columbia University) and The Echo Nest.\n",
    "\n",
    "\n",
    "Copyright 2010, Thierry Bertin-Mahieux\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import tables\n",
    "\n",
    "\n",
    "def open_h5_file_read(h5filename):\n",
    "    \"\"\"\n",
    "    Open an existing H5 in read mode.\n",
    "    Same function as in hdf5_utils, here so we avoid one import\n",
    "    \"\"\"\n",
    "    return tables.openFile(h5filename, mode='r')\n",
    "\n",
    "\n",
    "def get_num_songs(h5):\n",
    "    \"\"\"\n",
    "    Return the number of songs contained in this h5 file, i.e. the number of rows\n",
    "    for all basic informations like name, artist, ...\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.nrows\n",
    "\n",
    "def get_artist_familiarity(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist familiarity from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_familiarity[songidx]\n",
    "\n",
    "def get_artist_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_hotttnesss[songidx]\n",
    "\n",
    "def get_artist_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_id[songidx]\n",
    "\n",
    "def get_artist_mbid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_mbid[songidx]\n",
    "\n",
    "def get_artist_playmeid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist playme id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_playmeid[songidx]\n",
    "\n",
    "def get_artist_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_7digitalid[songidx]\n",
    "\n",
    "def get_artist_latitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist latitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_latitude[songidx]\n",
    "\n",
    "def get_artist_longitude(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist longitude from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_longitude[songidx]\n",
    "\n",
    "def get_artist_location(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist location from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_location[songidx]\n",
    "\n",
    "def get_artist_name(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist name from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_name[songidx]\n",
    "\n",
    "def get_release(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.release[songidx]\n",
    "\n",
    "def get_release_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.release_7digitalid[songidx]\n",
    "\n",
    "def get_song_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_id[songidx]\n",
    "\n",
    "def get_song_hotttnesss(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song hotttnesss from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_hotttnesss[songidx]\n",
    "\n",
    "def get_title(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get title from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.title[songidx]\n",
    "\n",
    "def get_track_7digitalid(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track 7digital id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.track_7digitalid[songidx]\n",
    "\n",
    "def get_similar_artists(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get similar artists array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:]\n",
    "    return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:\n",
    "                                            h5.root.metadata.songs.cols.idx_similar_artists[songidx+1]]\n",
    "\n",
    "def get_artist_terms(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                            h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_artist_terms_freq(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                              h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_artist_terms_weight(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.metadata.songs.nrows == songidx + 1:\n",
    "        return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n",
    "    return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n",
    "                                                h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n",
    "\n",
    "def get_analysis_sample_rate(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get analysis sample rate from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.analysis_sample_rate[songidx]\n",
    "\n",
    "def get_audio_md5(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get audio MD5 from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.audio_md5[songidx]\n",
    "\n",
    "def get_danceability(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get danceability from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.danceability[songidx]\n",
    "\n",
    "def get_duration(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get duration from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.duration[songidx]\n",
    "\n",
    "def get_end_of_fade_in(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get end of fade in from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.end_of_fade_in[songidx]\n",
    "\n",
    "def get_energy(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get energy from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.energy[songidx]\n",
    "\n",
    "def get_key(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.key[songidx]\n",
    "\n",
    "def get_key_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get key confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.key_confidence[songidx]\n",
    "\n",
    "def get_loudness(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get loudness from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.loudness[songidx]\n",
    "\n",
    "def get_mode(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.mode[songidx]\n",
    "\n",
    "def get_mode_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get mode confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.mode_confidence[songidx]\n",
    "\n",
    "def get_start_of_fade_out(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get start of fade out from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.start_of_fade_out[songidx]\n",
    "\n",
    "def get_tempo(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tempo from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.tempo[songidx]\n",
    "\n",
    "def get_time_signature(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.time_signature[songidx]\n",
    "\n",
    "def get_time_signature_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get signature confidence from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.time_signature_confidence[songidx]\n",
    "\n",
    "def get_track_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get track id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.track_id[songidx]\n",
    "\n",
    "def get_segments_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:]\n",
    "    return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:\n",
    "                                           h5.root.analysis.songs.cols.idx_segments_start[songidx+1]]\n",
    "    \n",
    "def get_segments_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:]\n",
    "    return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:\n",
    "                                                h5.root.analysis.songs.cols.idx_segments_confidence[songidx+1]]\n",
    "\n",
    "def get_segments_pitches(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments pitches array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:,:]\n",
    "    return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:\n",
    "                                             h5.root.analysis.songs.cols.idx_segments_pitches[songidx+1],:]\n",
    "\n",
    "def get_segments_timbre(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments timbre array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:,:]\n",
    "    return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:\n",
    "                                            h5.root.analysis.songs.cols.idx_segments_timbre[songidx+1],:]\n",
    "\n",
    "def get_segments_loudness_max(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness max array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:\n",
    "                                                  h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx+1]]\n",
    "\n",
    "def get_segments_loudness_max_time(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness max time array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:\n",
    "                                                       h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx+1]]\n",
    "\n",
    "def get_segments_loudness_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get segments loudness start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:]\n",
    "    return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:\n",
    "                                                    h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx+1]]\n",
    "\n",
    "def get_sections_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get sections start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:]\n",
    "    return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:\n",
    "                                           h5.root.analysis.songs.cols.idx_sections_start[songidx+1]]\n",
    "\n",
    "def get_sections_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get sections confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:]\n",
    "    return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:\n",
    "                                                h5.root.analysis.songs.cols.idx_sections_confidence[songidx+1]]\n",
    "\n",
    "def get_beats_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get beats start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:]\n",
    "    return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:\n",
    "                                        h5.root.analysis.songs.cols.idx_beats_start[songidx+1]]\n",
    "\n",
    "def get_beats_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get beats confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:]\n",
    "    return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:\n",
    "                                             h5.root.analysis.songs.cols.idx_beats_confidence[songidx+1]]\n",
    "\n",
    "def get_bars_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get bars start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:]\n",
    "    return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:\n",
    "                                       h5.root.analysis.songs.cols.idx_bars_start[songidx+1]]\n",
    "\n",
    "def get_bars_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get bars start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:]\n",
    "    return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:\n",
    "                                            h5.root.analysis.songs.cols.idx_bars_confidence[songidx+1]]\n",
    "\n",
    "def get_tatums_start(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tatums start array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:]\n",
    "    return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:\n",
    "                                         h5.root.analysis.songs.cols.idx_tatums_start[songidx+1]]\n",
    "\n",
    "def get_tatums_confidence(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tatums confidence array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.analysis.songs.nrows == songidx + 1:\n",
    "        return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:]\n",
    "    return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:\n",
    "                                              h5.root.analysis.songs.cols.idx_tatums_confidence[songidx+1]]\n",
    "\n",
    "def get_artist_mbtags(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n",
    "\n",
    "def get_artist_mbtags_count(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag count array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags_count[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags_count[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                                   h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n",
    "\n",
    "def get_year(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release year from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.musicbrainz.songs.cols.year[songidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca97d619",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'open_h5_file_read' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mopen_h5_file_read\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/Project_gp4/projectdata/MillionSongSubset/A/A/M/TRAAMES128F42AF068.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'open_h5_file_read' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1343b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
